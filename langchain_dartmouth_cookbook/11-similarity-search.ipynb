{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous recipe](10-embeddings.ipynb), we saw how to obtain embedding vectors for text of various lengths. We also learned that Large Language Models (LLMs) usually don't require us to determine the embeddings first, because they have their own embedding layer.\n",
    "\n",
    "However, there are several benefits to having the embedding of a word. An important one is that it gives us the ability to compare the _meaning_ of two words. One way of doing so is by taking the **dot product** of their corresponding embedding vectors $\\vec{v}$ and $\\vec{w}$:\n",
    "\n",
    "$$\n",
    "\\text{Similarity} = \\vec{v} \\cdot \\vec{w}\n",
    "$$\n",
    "\n",
    "First, let's embed some words, just like we learned in the previous recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_dartmouth.embeddings import DartmouthEmbeddings\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "embeddings = DartmouthEmbeddings(model_name=\"bge-large-en-v1-5\")\n",
    "text_1 = \"Japan\"\n",
    "text_2 = \"Sushi\"\n",
    "text_3 = \"Italy\"\n",
    "text_4 = \"Pizza\"\n",
    "\n",
    "embed_1 = embeddings.embed_query(text_1)\n",
    "embed_2 = embeddings.embed_query(text_2)\n",
    "embed_3 = embeddings.embed_query(text_3)\n",
    "embed_4 = embeddings.embed_query(text_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the dot product:\n",
    "$$\n",
    "\\vec{v}\\cdot \\vec{w} = \\sum_{i = 1}^N(v_i \\cdot w_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v, w):\n",
    "    similarity = sum(vi * wi for vi, wi in zip(v, w))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Similarity between {text_1} and {text_2} is {dot_product(embed_1, embed_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value for the similarity between these two words does not necessarily tell us a whole lot about their relationship. However, we can calculate the similarity between all the words to get a similarity ranking of sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Similarity between {text_1} and {text_3} is {dot_product(embed_1, embed_3)}\")\n",
    "print(f\"Similarity between {text_1} and {text_4} is {dot_product(embed_1, embed_4)}\")\n",
    "print(f\"Similarity between {text_2} and {text_3} is {dot_product(embed_2, embed_3)}\")\n",
    "print(f\"Similarity between {text_2} and {text_4} is {dot_product(embed_2, embed_4)}\")\n",
    "print(f\"Similarity between {text_3} and {text_4} is {dot_product(embed_3, embed_4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we observe that **Japan** and *Sushi* share a similarity comparable to that of **Italy** and *Pizza*. Likewise, **Italy** and *Sushi* as well as **Japan** and *Pizza* exhibit similar levels of association. Interestingly, **Japan** and **Italy** also demonstrate a high degree of similarity, likely because both are countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "This is an example of how *bias* leaks into for machine learning models. These results do not mean that you can't get good sushi in Italy or good pizza in Japan, or that those foods don't \"belong\" there. It simply means that in the training data for this embedding model, the words \"Italy\" and \"Pizza\" appeared more frequently in the same context as \"Italy\" and \"Sushi\".\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Similarity\n",
    "Visualizing embeddings can help a human observer quickly identify clusters of similar words. Let's generate some random words related to different domains, and find their embeddings. In the [recipe on building chains](./08-building-chains.ipynb), the idea of a pipeline was introduced. We use this to generate and parse the output of an llm to quickly get our test words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "\n",
    "\n",
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\", seed=42, temperature=0.0)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "\n",
    "response = chain.invoke(\n",
    "    \"Generate 30 different words that are well-suited to showcase how word embeddings work. \"\n",
    "    \"Draw the words from domains like animals, finance, and food. The food one should contain tomato \"\n",
    "    \"Return the words in JSON format, using the domain as the key, and the words as values. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put the words into a pandas DataFrame to get a nice table with all the information side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame.from_dict(response).melt(var_name=\"domain\", value_name=\"word\")\n",
    "\n",
    "embeddings = DartmouthEmbeddings(model_name=\"bge-large-en-v1-5\")\n",
    "words[\"embedding\"] = embeddings.embed_documents(words[\"word\"])\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "It is difficult to visualize a 1024-dimensional vector, as we're not 1024-dimensional humans! One way to get around this is by using a [UMAP](https://umap-learn.readthedocs.io/en/latest/) (Uniform Manifold Approximation and Projection) to represent this high-dimensional vector as a two-dimesional one. \n",
    "\n",
    "Don't worry if the code in the next cell looks complicated. Just assume that the UMAP does the dimensionality reduction in a way that preserves the \"closeness\" of the high-dimensional vectors: Vectors that were similar in the high-dimensional space are mapped to points that are close together in the two-dimensional space. You can learn more about the UMAP library in [its user guide](https://umap-learn.readthedocs.io/en/latest/).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "embeddings_list = words[\"embedding\"].to_list()\n",
    "mapper = umap.UMAP().fit(embeddings_list)\n",
    "umap_embeddings = pd.DataFrame(\n",
    "    mapper.transform(embeddings_list), columns=[\"UMAP_x\", \"UMAP_y\"]\n",
    ")\n",
    "\n",
    "words = pd.concat([words, umap_embeddings], axis=1)\n",
    "\n",
    "words.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have projected the embedding vectors into two dimensions `UMAP_x` and `UMAP_y`, we can visualize them in a common scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(words, x=\"UMAP_x\", y=\"UMAP_y\", color=\"domain\", hover_data=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "Move your mouse cursor over the individual data points to show the word it represents!\n",
    "```\n",
    "\n",
    "We can see that words are somewhat close to the other words in the same domain, with good separation from the other domains. This matches our intuition, and illustrates how embeddings capture semantic similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This recipe showed how to find the similarity between two embeddings. Visualizing embeddings can be a good way to represent this similarity. UMAP can be used to represent high-dimensional embeddings in a 2D plane, so we can easily visualize embeddings, and see their similarities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
