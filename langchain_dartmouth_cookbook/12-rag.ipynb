{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augemented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Retrievel augmented generation is a form of querying an LLM by providing some documents for additional context. For example, if you want the LLM to answer some questions based on specific documents you have, you can write a RAG model to do just that. \n",
    "\n",
    "A RAG model is primarily made up of two components, the retriever, and the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain_dartmouth.retrievers.document_compressors import DartmouthReranker\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory ./rag_documents contains different documents on various topics. Using the `TextLoader` from langchain, we can import these documents. Langchain has various different loaders for different file types. You can learn more about them [here](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_to_search = \"./rag_documents\"\n",
    "\n",
    "document_directories = [file for file in os.listdir(directory_to_search) if file.endswith('.txt')]\n",
    "document_directories = [os.path.join(directory_to_search, file) for file in document_directories]\n",
    "print(document_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "docs = []\n",
    "for directory in document_directories:\n",
    "    text_loader = TextLoader(directory, encoding='utf-8')\n",
    "    docs += text_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Given a **collection** of documents, we are interested in finding the ones most relevent to our question. To determine this, we can use the `DartmouthReranker` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = DartmouthReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "\n",
    "query = \"Are asteroids going to hit me?\"\n",
    "ranked_docs = reranker.compress_documents(query=query, documents=docs)\n",
    "\n",
    "for doc in ranked_docs:\n",
    "    print(doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** We can see that when our query is related to asteroids, the document correcly ranks the asteroids.txt as the most relevent document. Now, we can prepend the content of the first ranked document to our query to get a response which considers the information in the document\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\")\n",
    "response = llm.invoke(ranked_docs[0].page_content + 'Considering this, answer the following question:' +  query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this recipe we use a query and `DartmouthReranker` to retrieve relative documents from a **collection**. We then content of the highest ranked document is prepended in a prompt to the llm. This is an implementation of retreival augmented generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
