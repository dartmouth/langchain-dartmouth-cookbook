{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Chains\n",
    "\n",
    "Applications built around Large Language Models (LLMs) often have a pipeline structure: Input is pre-processed into a prompt, the model is invoked using this prompt, and the model's response may be post-processed to generate the desired output data structure or format.\n",
    "\n",
    "This pattern can be abstractly represented as a chain of transformations, where each transformation is handled by invoking a component. Let's re-use one of the chains from the [previous recipe on output parsing](05-output-parsing.ipynb). Let's also apply [a prompt template](07-prompt-templates.ipynb) instead of using basic string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 1928, 'event': 'Fisher Ames Baker Memorial Library opened with 240,000 volumes'}\n",
      "{'year': 1941, 'event': 'Library facility expanded'}\n",
      "{'year': 1957, 'event': 'Library facility expanded (continued from 1958)'}\n",
      "{'year': 1970, 'event': 'Received one millionth volume'}\n",
      "{'year': 1992, 'event': 'Donation of $30 million for new facility construction'}\n",
      "{'year': 2000, 'event': 'Baker-Berry Library opened'}\n",
      "{'year': 2002, 'event': 'Baker-Berry Library completed'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "UNSTRUCTURED_TEXT = \"\"\"The original, historic library building is the Fisher Ames Baker Memorial Library; it opened in 1928 with a collection of 240,000 volumes. The building was designed by Jens Fredrick Larson, modeled after Independence Hall in Philadelphia, and funded by a gift to Dartmouth College by George Fisher Baker in memory of his uncle, Fisher Ames Baker, Dartmouth class of 1859. The facility was expanded in 1941 and 1957â€“1958 and received its one millionth volume in 1970.\n",
    "\n",
    "In 1992, John Berry and the Baker family donated US $30 million for the construction of a new facility, the Berry Library designed by architect Robert Venturi, adjoining the Baker Library. The new complex, the Baker-Berry Library, opened in 2000 and was completed in 2002.[6] The Dartmouth College libraries presently hold over 2 million volumes in their collections.\"\"\"\n",
    "\n",
    "\n",
    "# Setting up the components\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract a succinct timeline of events directly related the Library from the following text. Return the timeline as a list of dictionaries, where each dictionary has two keys: 'year' and 'event'. Format your output in JSON format. The text: \\n\\n{unstructured_text}\"\n",
    ")\n",
    "\n",
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\")\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Invoking the components in sequence\n",
    "formatted_prompt = prompt.invoke({\"unstructured_text\": UNSTRUCTURED_TEXT})\n",
    "llm_response = llm.invoke(formatted_prompt)\n",
    "timeline = parser.invoke(llm_response)\n",
    "\n",
    "# Print the events in the timeline\n",
    "for event in timeline:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the final result is indeed generated by invoking each component with the output of the previous component. To make this sequential processing more elegant, LangChain offers the concept of _chains_. We compose chains by concatenating the components with the `|` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_extraction_chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chain we just created can now be invoked with the input required by the first component and produces the output of the final component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 1928,\n",
       "  'event': 'The Fisher Ames Baker Memorial Library opened with a collection of 240,000 volumes.'},\n",
       " {'year': 1941, 'event': 'The library building was expanded.'},\n",
       " {'year': 1957, 'event': 'The library building was further expanded.'},\n",
       " {'year': 1958, 'event': \"The library building's expansion was completed.\"},\n",
       " {'year': 1970, 'event': 'The library received its one millionth volume.'},\n",
       " {'year': 1992,\n",
       "  'event': 'John Berry and the Baker family donated US $30 million for the construction of a new library facility.'},\n",
       " {'year': 2000, 'event': 'The new Baker-Berry Library complex opened.'},\n",
       " {'year': 2002, 'event': 'The Baker-Berry Library complex was completed.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeline_extraction_chain.invoke({\"unstructured_text\": UNSTRUCTURED_TEXT})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "When stringing together components with the `|` operator, we can replace a sequence of calls to the various components' `invoke` methods with a single call to `chain.invoke`. This is the main benefit of using chains: they allow us to compose multiple components into a single pipeline that can be invoked in one call."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
