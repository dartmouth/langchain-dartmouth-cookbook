{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "Before a large language model (LLM) can understand and predict words, it first needs to convert them into numbers through a process called \"embedding.\" This is like representing each word as a collection of sliders—imagine a graphic equalizer for sound—where each slider setting captures some aspect of the word's meaning. \n",
    "\n",
    "For example, words like \"nice\" and \"stupendous\" might have similar settings on a \"positivity\" slider but differ on an \"intensity\" slider. These sliders help the model figure out how words relate to each other. \n",
    "\n",
    "A word's embedding involves many of these sliders—possibly thousands—but we don't actually know what each individual slider represents in terms of meaning. The large number of sliders helps the model better understand complex relationships between words, even if we can't clearly label each one. \n",
    "\n",
    "[This](https://www.youtube.com/shorts/FJtFZwbvkI4) short video explains this concept in an intuitive way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Embedding\n",
    "\n",
    "Let's find an embedding for a word of our choosing. We will be looking into static embeddings, which are fixed representations of words as vectors from a pre-trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_dartmouth.embeddings import DartmouthEmbeddings\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for embeddings is different class from the ones that we have used before. We can see how it's used below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = DartmouthEmbeddings()\n",
    "\n",
    "word = embeddings.embed_query(\"tiger\")\n",
    "print(word)\n",
    "print(\"Length of embedding: \", len(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** We see that the word \"tiger\" is represented by a list of 1024 numbers. This means that the numeric representation of the word \"tiger\" consists of 1024 dimensions (or sliders) for this particular embedding model. Other models may use fewer or more numbers to represent text. You can read more about the model we are using [here](https://huggingface.co/BAAI/bge-large-en-v1.5)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextLoaders\n",
    "The embed_documents function allows embedding multiple tokens as a list. It also supports embedding `Document` class objects in LangChain. Using `TextLoader`, you can import various different types of files as a `Document` class. LangChain offers specialized loaders for different file types. Learn more about these loaders [here](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "directory_to_file = './rag_documents/asteroids.txt'\n",
    "text_loader = TextLoader(directory_to_file)\n",
    "document = text_loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the text in the document can be **tokenized** in any way we like. A conceptually easy way to do so is by embedding each word. However, documents generally have a lot of words, and `embed_documents` only accepts a specific number of strings in one go. An example of this error is given below, where the maximum number is 512. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting embedding 33 words\n",
    "words = document[0].page_content.split(' ')\n",
    "\n",
    "try:\n",
    "    responses = embeddings.embed_documents(words)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get by this issue, we can feed in 512 words at a time, and repeat until we are done with all the words that are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "\n",
    "for i in range(0, len(words), 512):\n",
    "    chunk = words[i:i+512]\n",
    "    embeded_chunk = embeddings.embed_documents(chunk)\n",
    "    embeddings_list += embeded_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of embeddings in the document: ', len(embeddings_list))\n",
    "print('First 5 embeddings:')\n",
    "for i in range(5):\n",
    "    print(f'{words[i]:<15}: {embeddings_list[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "Embeddings are representation of strings as numbers. Using the `embed_query` and `embed_documents` functions, we can get the embeddings of words or phrases. This lets us do many exciting operations to represent how different words are related to each other.\n",
    "\n",
    "With `embed_documents` we can take advantage of LangChain's `Document` class to embed entire files. \n",
    "\n",
    "The batch size of the default embedding model is 512 tokens. This can be bypassed by feeding in 512 strings at a time. The batch size is dependent on the model being used.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
